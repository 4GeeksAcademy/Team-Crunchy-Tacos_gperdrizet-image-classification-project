{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification: cats & dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports up-front\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the training data\n",
    "training_data_path='../data/train'\n",
    "\n",
    "# Get a list of training dog and cat images\n",
    "training_dogs=glob.glob(f'{training_data_path}/dog/dog.*')\n",
    "training_cats=glob.glob(f'{training_data_path}/cat/cat.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2,figsize=(6, 4))\n",
    "\n",
    "for cat, dog, row in zip(training_cats, training_dogs, axs):\n",
    "    for animal, ax in zip([cat, dog], row):\n",
    "        animal=image.load_img(animal)\n",
    "        animal=image.img_to_array(animal)\n",
    "        animal/=255.0\n",
    "        ax.imshow(animal)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Let's take a look at a few of our images to get a feel for how image data is structured.\n",
    "\n",
    "### 2.1. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one of the dogs\n",
    "dog=image.load_img(training_dogs[0])\n",
    "\n",
    "# And convert it to an array - this is how TensorFlow will handel the data\n",
    "dog=image.img_to_array(dog)\n",
    "\n",
    "# Take a look at some properites of the object\n",
    "print(f'Image data is: {type(dog)}')\n",
    "print(f'Image data shape: {dog.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has shape of 500 x 390 x 3? So, the image is 500 x 390 pixles, but what is the 3? Let's plot the pixle values and you will see what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dog[:,:,0].flatten(), bins=100, color='red', alpha=0.5, label='Red channel')\n",
    "plt.hist(dog[:,:,1].flatten(), bins=100, color='green', alpha=0.5, label='Green channel')\n",
    "plt.hist(dog[:,:,2].flatten(), bins=100, color='blue', alpha=0.5, label='Blue channel')\n",
    "plt.xlabel('Pixel value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few intresting observations we can make here:\n",
    "\n",
    "1. This array has 3 axies: 500 x 390 x 3. The first two are the dimensions of the image, the third is the three color channels: red, green and blue\n",
    "2. 500 x 390 x 3 is over a half million individual values - this one image is 10 time more data that any of the other datasets we have worked with so far!\n",
    "3. The range of pixle values is from 0 to about 250 - in reality it is (0,255) for a total range of 256 values per pixle. This is defined by the JPEG image standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Image dimensions\n",
    "\n",
    "Let's take a look at a random sample of images from the dataset and see what their dimensions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size=1000\n",
    "sample=random.sample(training_dogs, sample_size//2)\n",
    "sample+=random.sample(training_cats, sample_size//2)\n",
    "\n",
    "heights=[]\n",
    "widths=[]\n",
    "\n",
    "for sample_image in sample:\n",
    "\n",
    "    sample_image=image.load_img(sample_image)\n",
    "    sample_image=image.img_to_array(sample_image)\n",
    "    heights.append(sample_image.shape[0])\n",
    "    widths.append(sample_image.shape[1])\n",
    "\n",
    "plt.hist(heights, bins=50, alpha=0.5, label='Image heights')\n",
    "plt.hist(widths, bins=50, alpha=0.5, label='Image widths')\n",
    "plt.xlabel('Image dimension')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above plot, let's set our image dimension at 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Image aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratios=np.array(widths)/np.array(heights)\n",
    "\n",
    "plt.hist(aspect_ratios, bins=50, color='black')\n",
    "plt.xlabel('Image aspect ratio')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model\n",
    "\n",
    "### 2.1. Prepare images for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(training_data_path: str, image_dim: int, batch_size: int=32):\n",
    "\n",
    "    training_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    validation_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    # AUTOTUNE=tf.data.AUTOTUNE\n",
    "\n",
    "    # training_dataset=training_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    # validation_dataset=validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return training_dataset, validation_dataset\n",
    "\n",
    "training_dataset, validation_dataset=make_datasets(training_data_path, image_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(image_dim, learning_rate):\n",
    "\n",
    "    initializer=tf.keras.initializers.GlorotUniform(seed=315)\n",
    "\n",
    "    model=Sequential([\n",
    "        layers.Input((image_dim, image_dim, 1)),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
    "    ])\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=compile_model(image_dim, 0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results=model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=10,\n",
    "  validation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up a 1x2 figure for accuracy and binary cross-entropy\n",
    "fig, axs=plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "# Add the main title\n",
    "fig.suptitle('CNN training curves')\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].set_title('Accuracy')\n",
    "axs[0].plot(np.array(training_results.history['binary_accuracy']) * 100, label='Training')\n",
    "axs[0].plot(np.array(training_results.history['val_binary_accuracy']) * 100, label='Validation')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy (%)')\n",
    "axs[0].legend(loc='upper left')\n",
    "\n",
    "# Plot training and validation binary cross-entropy\n",
    "axs[1].set_title('Binary cross-entropy')\n",
    "axs[1].plot(training_results.history['loss'])\n",
    "axs[1].plot(training_results.history['val_loss'])\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Binary cross-entropy')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[0.001,0.0001,0.00001]\n",
    "batch_sizes=[32,64,128,256]\n",
    "training_results=[]\n",
    "\n",
    "conditions=list(itertools.product(batch_sizes, learning_rates))\n",
    "\n",
    "for i, parameters in enumerate(conditions):\n",
    "\n",
    "    batch_size, learning_rate=parameters\n",
    "\n",
    "    print(f'\\nStarting training run {i + 1} of {len(learning_rates) * len(batch_sizes)}: batch size: {batch_size}, learning rate: {learning_rate}')\n",
    "\n",
    "    training_dataset, validation_dataset=make_datasets(training_data_path, image_dim, batch_size)\n",
    "    model=compile_model(image_dim, learning_rate)\n",
    "\n",
    "    early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "    training_result=model.fit(\n",
    "        training_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=10,\n",
    "        validation_steps=5,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    training_results.append(training_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up a 1x2 figure for accuracy and binary cross-entropy\n",
    "fig, axs=plt.subplots(len(training_results), 2, figsize=(8,3*len(training_results)))\n",
    "\n",
    "# Add the main title\n",
    "fig.suptitle('CNN training curves', size='large')\n",
    "\n",
    "# Plot the results of each training run\n",
    "for i, parameters in enumerate(conditions):\n",
    "    batch_size, learning_rate=parameters\n",
    "    training_result=training_results[i]\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    axs[i,0].set_title(f'Accuracy\\nbatch size = {batch_size}, learning rate = {learning_rate}')\n",
    "    axs[i,0].plot(np.array(training_result.history['binary_accuracy']) * 100, label='Training')\n",
    "    axs[i,0].plot(np.array(training_result.history['val_binary_accuracy']) * 100, label='Validation')\n",
    "    axs[i,0].set_xlabel('Epoch')\n",
    "    axs[i,0].set_ylabel('Accuracy (%)')\n",
    "    axs[i,0].legend(loc='best')\n",
    "\n",
    "    # Plot training and validation binary cross-entropy\n",
    "    axs[i,1].set_title(f'Binary cross-entropy\\nbatch size = {batch_size}, learning rate = {learning_rate}')\n",
    "    axs[i,1].plot(training_result.history['loss'], label='Training')\n",
    "    axs[i,1].plot(training_result.history['val_loss'], label='Validation')\n",
    "    axs[i,1].set_xlabel('Epoch')\n",
    "    axs[i,1].set_ylabel('Binary cross-entropy')\n",
    "    axs[i,1].legend(loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
